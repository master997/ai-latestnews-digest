"""Markdown digest generator module."""

import json
import os
from datetime import datetime
from pathlib import Path

from .scraper import Article


def group_articles(articles: list[Article]) -> dict[str, list[Article]]:
    """
    Sort and group articles by relevance tier.

    Returns:
        Dict with keys 'high', 'medium', 'other', each containing
        a list of Article objects sorted by relevance_score descending.
    """
    sorted_articles = sorted(
        articles,
        key=lambda x: x.relevance_score,
        reverse=True
    )
    return {
        "high": [a for a in sorted_articles if a.relevance_score >= 0.7],
        "medium": [a for a in sorted_articles if 0.4 <= a.relevance_score < 0.7],
        "other": [a for a in sorted_articles if a.relevance_score < 0.4],
    }


def save_digest_json(
    articles: list[Article],
    topic: str,
    output_dir: str = "./digests"
) -> str:
    """Save article data as JSON for web UI consumption."""
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    date_str = datetime.now().strftime("%Y-%m-%d")
    filepath = os.path.join(output_dir, f"digest_{date_str}.json")

    data = {
        "date": date_str,
        "topic": topic,
        "generated": datetime.now().isoformat(),
        "articles": [
            {
                "title": a.title,
                "link": a.link,
                "source": a.source,
                "published": a.published.isoformat() if a.published else None,
                "description": a.description,
                "summary": a.summary,
                "relevance_score": a.relevance_score,
            }
            for a in articles
        ],
    }

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)

    return filepath


def generate_digest(
    articles: list[Article],
    topic: str,
    output_dir: str = "./digests"
) -> str:
    """
    Generate a markdown digest file from processed articles.

    Args:
        articles: List of processed Article objects
        topic: Topic used for relevance ranking
        output_dir: Directory to save the digest file

    Returns:
        Path to the generated markdown file
    """
    # Create output directory if it doesn't exist
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Generate filename with current date
    date_str = datetime.now().strftime("%Y-%m-%d")
    filename = f"digest_{date_str}.md"
    filepath = os.path.join(output_dir, filename)

    # Group articles by relevance tier
    groups = group_articles(articles)
    high_relevance = groups["high"]
    medium_relevance = groups["medium"]
    other = groups["other"]

    # Build markdown content
    lines = [
        f"# AI News Digest - {date_str}",
        "",
        f"> Daily digest of articles related to **{topic}**",
        f"> Generated on {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
        "---",
        "",
        f"## Top Stories ({len(articles)} articles)",
        "",
    ]

    if high_relevance:
        lines.append("### Highly Relevant")
        lines.append("")
        for article in high_relevance:
            lines.extend(format_article(article))

    if medium_relevance:
        lines.append("### Related")
        lines.append("")
        for article in medium_relevance:
            lines.extend(format_article(article))

    if other:
        lines.append("### Other News")
        lines.append("")
        for article in other:
            lines.extend(format_article(article))

    # Add footer
    lines.extend([
        "---",
        "",
        "*Generated by AI News Digest CLI*",
    ])

    # Write to file
    content = "\n".join(lines)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)

    # Also save JSON sidecar for web UI
    save_digest_json(articles, topic, output_dir)

    return filepath


def format_article(article: Article) -> list[str]:
    """
    Format a single article for markdown output.

    Args:
        article: Article object to format

    Returns:
        List of markdown lines
    """
    lines = []

    # Title with link
    lines.append(f"#### [{article.title}]({article.link})")
    lines.append("")

    # Metadata
    meta_parts = [f"**Source:** {article.source}"]
    if article.published:
        meta_parts.append(f"**Published:** {article.published.strftime('%Y-%m-%d')}")
    meta_parts.append(f"**Relevance:** {article.relevance_score:.0%}")
    lines.append(" | ".join(meta_parts))
    lines.append("")

    # Summary
    if article.summary:
        lines.append(f"> {article.summary}")
        lines.append("")

    lines.append("")

    return lines


def print_digest_summary(articles: list[Article], topic: str) -> None:
    """
    Print a summary of the digest to console.

    Args:
        articles: List of processed Article objects
        topic: Topic used for relevance ranking
    """
    sorted_articles = sorted(
        articles,
        key=lambda x: x.relevance_score,
        reverse=True
    )

    print(f"\n{'='*60}")
    print(f"AI NEWS DIGEST - {datetime.now().strftime('%Y-%m-%d')}")
    print(f"Topic: {topic}")
    print(f"{'='*60}\n")

    for i, article in enumerate(sorted_articles[:10], 1):
        relevance_bar = "█" * int(article.relevance_score * 10) + "░" * (10 - int(article.relevance_score * 10))
        print(f"{i}. [{relevance_bar}] {article.title[:60]}...")
        print(f"   Source: {article.source} | Relevance: {article.relevance_score:.0%}")
        if article.summary:
            summary_preview = article.summary[:100] + "..." if len(article.summary) > 100 else article.summary
            print(f"   {summary_preview}")
        print()
